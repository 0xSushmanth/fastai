---

title: AWD-LSTM


keywords: fastai
sidebar: home_sidebar

summary: "AWD LSTM from <a href='https://arxiv.org/pdf/1708.02182.pdf'>Smerity et al.</a> "
description: "AWD LSTM from <a href='https://arxiv.org/pdf/1708.02182.pdf'>Smerity et al.</a> "
nb_path: "nbs/32_text.models.awdlstm.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/32_text.models.awdlstm.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Basic-NLP-modules">Basic NLP modules<a class="anchor-link" href="#Basic-NLP-modules"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>On top of the pytorch or the fastai <a href="/layers.html"><code>layers</code></a>, the language models use some custom layers specific to NLP.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="dropout_mask" class="doc_header"><code>dropout_mask</code><a href="https://github.com/fastai/fastai/tree/master/fastai/text/models/awdlstm.py#L16" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>dropout_mask</code>(<strong><code>x</code></strong>:<code>Tensor</code>, <strong><code>sz</code></strong>:<code>list</code>, <strong><code>p</code></strong>:<code>float</code>)</p>
</blockquote>
<p>Return a dropout mask of the same type as <code>x</code>, size <code>sz</code>, with probability <code>p</code> to cancel an element.</p>
<table>
<thead><tr>
<th></th>
<th>Type</th>
<th>Default</th>
<th>Details</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><code>x</code></strong></td>
<td><code>Tensor</code></td>
<td></td>
<td>Source tensor, output will be of the same type as <code>x</code></td>
</tr>
<tr>
<td><strong><code>sz</code></strong></td>
<td><code>list</code></td>
<td></td>
<td>Size of the dropout mask as <code>int</code>s</td>
</tr>
<tr>
<td><strong><code>p</code></strong></td>
<td><code>float</code></td>
<td></td>
<td>Dropout probability</td>
</tr>
</tbody>
</table>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">t</span> <span class="o">=</span> <span class="n">dropout_mask</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="mf">0.25</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="k">assert</span> <span class="p">((</span><span class="n">t</span> <span class="o">==</span> <span class="mi">4</span><span class="o">/</span><span class="mi">3</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">t</span><span class="o">==</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h3 id="RNNDropout" class="doc_header"><code>class</code> <code>RNNDropout</code><a href="https://github.com/fastai/fastai/tree/master/fastai/text/models/awdlstm.py#L25" class="source_link" style="float:right">[source]</a></h3><blockquote><p><code>RNNDropout</code>(<strong><code>p</code></strong>:<code>float</code>=<em><code>0.5</code></em>) :: <a href="/torch_core.html#Module"><code>Module</code></a></p>
</blockquote>
<p>Dropout with probability <code>p</code> that is consistent on the seq_len dimension.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dp</span> <span class="o">=</span> <span class="n">RNNDropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">tst_inp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">7</span><span class="p">)</span>
<span class="n">tst_out</span> <span class="o">=</span> <span class="n">dp</span><span class="p">(</span><span class="n">tst_inp</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">7</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">tst_out</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="k">assert</span> <span class="p">(</span><span class="n">tst_out</span><span class="p">[</span><span class="n">i</span><span class="p">,:,</span><span class="n">j</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span> <span class="n">test_close</span><span class="p">(</span><span class="n">tst_out</span><span class="p">[</span><span class="n">i</span><span class="p">,:,</span><span class="n">j</span><span class="p">],</span> <span class="n">tst_inp</span><span class="p">[</span><span class="n">i</span><span class="p">,:,</span><span class="n">j</span><span class="p">]</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="mf">0.3</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It also supports doing dropout over a sequence of images where time dimesion is the 1st axis, 10 images of 3 channels and 32 by 32.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">dp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h3 id="WeightDropout" class="doc_header"><code>class</code> <code>WeightDropout</code><a href="https://github.com/fastai/fastai/tree/master/fastai/text/models/awdlstm.py#L34" class="source_link" style="float:right">[source]</a></h3><blockquote><p><code>WeightDropout</code>(<strong><code>module</code></strong>:<code>nn.Module</code>, <strong><code>weight_p</code></strong>:<code>float</code>, <strong><code>layer_names</code></strong>:<code>(str, list)</code>=<em><code>'weight_hh_l0'</code></em>) :: <a href="/torch_core.html#Module"><code>Module</code></a></p>
</blockquote>
<p>A module that wraps another layer in which some weights will be replaced by 0 during training.</p>
<table>
<thead><tr>
<th></th>
<th>Type</th>
<th>Default</th>
<th>Details</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><code>module</code></strong></td>
<td><code>nn.Module</code></td>
<td></td>
<td>Wrapped module</td>
</tr>
<tr>
<td><strong><code>weight_p</code></strong></td>
<td><code>float</code></td>
<td></td>
<td>Weight dropout probability</td>
</tr>
<tr>
<td><strong><code>layer_names</code></strong></td>
<td><code>(str, list)</code></td>
<td><code>weight_hh_l0</code></td>
<td>Name(s) of the parameters to apply dropout to</td>
</tr>
</tbody>
</table>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">module</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">7</span><span class="p">)</span>
<span class="n">dp_module</span> <span class="o">=</span> <span class="n">WeightDropout</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">)</span>
<span class="n">wgts</span> <span class="o">=</span> <span class="n">dp_module</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">weight_hh_l0</span>
<span class="n">tst_inp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">7</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">7</span><span class="p">)</span>
<span class="n">dp_module</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="n">x</span><span class="p">,</span><span class="n">h</span> <span class="o">=</span> <span class="n">dp_module</span><span class="p">(</span><span class="n">tst_inp</span><span class="p">,</span><span class="n">h</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">new_wgts</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">dp_module</span><span class="o">.</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;weight_hh_l0&#39;</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">wgts</span><span class="p">,</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">dp_module</span><span class="p">,</span> <span class="s1">&#39;weight_hh_l0_raw&#39;</span><span class="p">))</span>
<span class="k">assert</span> <span class="mf">0.2</span> <span class="o">&lt;=</span> <span class="p">(</span><span class="n">new_wgts</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">/</span><span class="n">new_wgts</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="mf">0.6</span>
<span class="k">assert</span> <span class="n">dp_module</span><span class="o">.</span><span class="n">weight_hh_l0_raw</span><span class="o">.</span><span class="n">requires_grad</span>
<span class="k">assert</span> <span class="n">dp_module</span><span class="o">.</span><span class="n">weight_hh_l0_raw</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
<span class="k">assert</span> <span class="p">((</span><span class="n">dp_module</span><span class="o">.</span><span class="n">weight_hh_l0_raw</span><span class="o">.</span><span class="n">grad</span> <span class="o">==</span> <span class="mf">0.</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">new_wgts</span> <span class="o">==</span> <span class="mf">0.</span><span class="p">))</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h3 id="EmbeddingDropout" class="doc_header"><code>class</code> <code>EmbeddingDropout</code><a href="https://github.com/fastai/fastai/tree/master/fastai/text/models/awdlstm.py#L76" class="source_link" style="float:right">[source]</a></h3><blockquote><p><code>EmbeddingDropout</code>(<strong><code>emb</code></strong>:<code>nn.Embedding</code>, <strong><code>embed_p</code></strong>:<code>float</code>) :: <a href="/torch_core.html#Module"><code>Module</code></a></p>
</blockquote>
<p>Apply dropout with probability <code>embed_p</code> to an embedding layer <code>emb</code>.</p>
<table>
<thead><tr>
<th></th>
<th>Type</th>
<th>Default</th>
<th>Details</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><code>emb</code></strong></td>
<td><code>nn.Embedding</code></td>
<td></td>
<td>Wrapped embedding layer</td>
</tr>
<tr>
<td><strong><code>embed_p</code></strong></td>
<td><code>float</code></td>
<td></td>
<td>Embdedding layer dropout probability</td>
</tr>
</tbody>
</table>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">enc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">enc_dp</span> <span class="o">=</span> <span class="n">EmbeddingDropout</span><span class="p">(</span><span class="n">enc</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">tst_inp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">,(</span><span class="mi">8</span><span class="p">,))</span>
<span class="n">tst_out</span> <span class="o">=</span> <span class="n">enc_dp</span><span class="p">(</span><span class="n">tst_inp</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">):</span>
    <span class="k">assert</span> <span class="p">(</span><span class="n">tst_out</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span> <span class="ow">or</span> <span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">tst_out</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="mi">2</span><span class="o">*</span><span class="n">enc</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="n">tst_inp</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h3 id="AWD_LSTM" class="doc_header"><code>class</code> <code>AWD_LSTM</code><a href="https://github.com/fastai/fastai/tree/master/fastai/text/models/awdlstm.py#L96" class="source_link" style="float:right">[source]</a></h3><blockquote><p><code>AWD_LSTM</code>(<strong><code>vocab_sz</code></strong>:<code>int</code>, <strong><code>emb_sz</code></strong>:<code>int</code>, <strong><code>n_hid</code></strong>:<code>int</code>, <strong><code>n_layers</code></strong>:<code>int</code>, <strong><code>pad_token</code></strong>:<code>int</code>=<em><code>1</code></em>, <strong><code>hidden_p</code></strong>:<code>float</code>=<em><code>0.2</code></em>, <strong><code>input_p</code></strong>:<code>float</code>=<em><code>0.6</code></em>, <strong><code>embed_p</code></strong>:<code>float</code>=<em><code>0.1</code></em>, <strong><code>weight_p</code></strong>:<code>float</code>=<em><code>0.5</code></em>, <strong><code>bidir</code></strong>:<code>bool</code>=<em><code>False</code></em>) :: <a href="/torch_core.html#Module"><code>Module</code></a></p>
</blockquote>
<p>AWD-LSTM inspired by <a href="https://arxiv.org/abs/1708.02182">https://arxiv.org/abs/1708.02182</a></p>
<table>
<thead><tr>
<th></th>
<th>Type</th>
<th>Default</th>
<th>Details</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><code>vocab_sz</code></strong></td>
<td><code>int</code></td>
<td></td>
<td>Size of the vocabulary</td>
</tr>
<tr>
<td><strong><code>emb_sz</code></strong></td>
<td><code>int</code></td>
<td></td>
<td>Size of embedding vector</td>
</tr>
<tr>
<td><strong><code>n_hid</code></strong></td>
<td><code>int</code></td>
<td></td>
<td>Number of features in hidden state</td>
</tr>
<tr>
<td><strong><code>n_layers</code></strong></td>
<td><code>int</code></td>
<td></td>
<td>Number of LSTM layers</td>
</tr>
<tr>
<td><strong><code>pad_token</code></strong></td>
<td><code>int</code></td>
<td><code>1</code></td>
<td>Padding token id</td>
</tr>
<tr>
<td><strong><code>hidden_p</code></strong></td>
<td><code>float</code></td>
<td><code>0.2</code></td>
<td>Dropout probability for hidden state between layers</td>
</tr>
<tr>
<td><strong><code>input_p</code></strong></td>
<td><code>float</code></td>
<td><code>0.6</code></td>
<td>Dropout probability for LSTM stack input</td>
</tr>
<tr>
<td><strong><code>embed_p</code></strong></td>
<td><code>float</code></td>
<td><code>0.1</code></td>
<td>Embedding layer dropout probabillity</td>
</tr>
<tr>
<td><strong><code>weight_p</code></strong></td>
<td><code>float</code></td>
<td><code>0.5</code></td>
<td>Hidden-to-hidden wight dropout probability for LSTM layers</td>
</tr>
<tr>
<td><strong><code>bidir</code></strong></td>
<td><code>bool</code></td>
<td><code>False</code></td>
<td>If set to <code>True</code> uses bidirectional LSTM layers</td>
</tr>
</tbody>
</table>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is the core of an AWD-LSTM model, with embeddings from <code>vocab_sz</code> and <code>emb_sz</code>, <code>n_layers</code> LSTMs potentially <code>bidir</code> stacked, the first one going from <code>emb_sz</code> to <code>n_hid</code>, the last one from <code>n_hid</code> to <code>emb_sz</code> and all the inner ones from <code>n_hid</code> to <code>n_hid</code>. <code>pad_token</code> is passed to the PyTorch embedding layer. The dropouts are applied as such:</p>
<ul>
<li>the embeddings are wrapped in <a href="/text.models.awdlstm.html#EmbeddingDropout"><code>EmbeddingDropout</code></a> of probability <code>embed_p</code>;</li>
<li>the result of this embedding layer goes through an <a href="/text.models.awdlstm.html#RNNDropout"><code>RNNDropout</code></a> of probability <code>input_p</code>;</li>
<li>each LSTM has <a href="/text.models.awdlstm.html#WeightDropout"><code>WeightDropout</code></a> applied with probability <code>weight_p</code>;</li>
<li>between two of the inner LSTM, an <a href="/text.models.awdlstm.html#RNNDropout"><code>RNNDropout</code></a> is applied with probability <code>hidden_p</code>.</li>
</ul>
<p>THe module returns two lists: the raw outputs (without being applied the dropout of <code>hidden_p</code>) of each inner LSTM and the list of outputs with dropout. Since there is no dropout applied on the last output, those two lists have the same last element, which is the output that should be fed to a decoder (in the case of a language model).</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tst</span> <span class="o">=</span> <span class="n">AWD_LSTM</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">hidden_p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">embed_p</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">input_p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">weight_p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">tst</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">tst</span><span class="o">.</span><span class="n">bs</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tst</span><span class="o">.</span><span class="n">hidden</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">([</span><span class="n">h_</span><span class="o">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">h_</span> <span class="ow">in</span> <span class="n">tst</span><span class="o">.</span><span class="n">hidden</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">]])</span>
<span class="n">test_eq</span><span class="p">([</span><span class="n">h_</span><span class="o">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">h_</span> <span class="ow">in</span> <span class="n">tst</span><span class="o">.</span><span class="n">hidden</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">20</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">20</span><span class="p">]])</span>

<span class="n">test_eq</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">20</span><span class="p">])</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">r</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">tst</span><span class="o">.</span><span class="n">hidden</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span> <span class="c1">#hidden state is the last timestep in raw outputs</span>

<span class="n">tst</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">tst</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="n">tst</span><span class="p">(</span><span class="n">x</span><span class="p">);</span>
<span class="n">tst</span><span class="p">(</span><span class="n">x</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="awd_lstm_lm_split" class="doc_header"><code>awd_lstm_lm_split</code><a href="https://github.com/fastai/fastai/tree/master/fastai/text/models/awdlstm.py#L164" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>awd_lstm_lm_split</code>(<strong><code>model</code></strong>)</p>
</blockquote>
<p>Split a RNN <code>model</code> in groups for differential learning rates.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="awd_lstm_clas_split" class="doc_header"><code>awd_lstm_clas_split</code><a href="https://github.com/fastai/fastai/tree/master/fastai/text/models/awdlstm.py#L175" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>awd_lstm_clas_split</code>(<strong><code>model</code></strong>)</p>
</blockquote>
<p>Split a RNN <code>model</code> in groups for differential learning rates.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

</div>
 

