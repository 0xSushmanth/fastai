{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|skip\n",
    "! [ -e /content ] && pip install -Uqq fastai  # upgrade fastai on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "#nbdev_comment from __future__ import annotations\n",
    "from fastai.basics import *\n",
    "from fastai.callback.progress import ProgressCallback\n",
    "from fastai.distributed import DistributedDL, rank0_first, setup_distrib, teardown_distrib\n",
    "from fastai.optimizer import OptimWrapper\n",
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accelerate and fastai\n",
    "\n",
    "> Callbacks and helper functions to train in distributed training or DeepSpeed with Accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to `fastai.distributed`, `fastai.accelerate` is an integration with the [Accelerate](https://github.com/huggingface/accelerate) framework, which aims to make it easy to use the same code on multiple CPU's, GPU's and TPU's (though unsupported currently in fastai). To use distributed training, there are only two required steps:\n",
    "\n",
    "1. Add `with learn.accelerated():` before your `learn.fit` call\n",
    "2. Run your training script with `accelerate launch scriptname.py ...args...`\n",
    "\n",
    "An initial configuration can be performed by running `accelerate config`, though ensure that **mixed_precision** should always be set to **no** as fastai's `Learner.to_fp16` should be used instead. \n",
    "\n",
    "See below for details on the full API and underlying helper functions, if needed -- however, note that you will not need anything except the above unless you need to change how the distributed training is implemented.\n",
    "\n",
    "Finally at the bottom is directions for how to utilize `Accelerate`'s `notebook_launcher` to launch distributed processes straight from a Jupyter Notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AcceleratedTrainer -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_hidden_params = [\"mixed_precision\", \"fp16\", \"log_with\", \"logging_dir\", \"step_scheduler_with_optimizer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class AcceleratedTrainer(Callback):\n",
    "    \"Wrap `model` in `DistributedDataParallel` and `dls` in `DistributedDL` to be used in the Accelerate framework\"\n",
    "    order = 11\n",
    "    @delegates(Accelerator, but=_hidden_params)\n",
    "    def __init__(self,\n",
    "        sync_bn=True, # Whether to replace all batch norm with `nn.SyncBatchNorm`\n",
    "        **kwargs\n",
    "    ):\n",
    "        store_attr()\n",
    "        self.accelerator = Accelerator(**kwargs)\n",
    "    def before_fit(self):\n",
    "        self.learn.model = self.accelerator.prepare(\n",
    "            nn.SyncBatchNorm.convert_sync_batchnorm(self.model) if self.sync_bn else self.model\n",
    "        )\n",
    "        self.old_dls, self.old_opt = list(self.dls), self.opt\n",
    "        self.learn.dls.loaders = [self._wrap_dl(dl) for dl in self.dls]\n",
    "        if rank_distrib(): self.learn.logger=noop\n",
    "\n",
    "    def _wrap_dl(self, dl):\n",
    "        return dl if isinstance(dl,DistributedDL) else DistributedDL(dl)\n",
    "    \n",
    "    def before_backward(self):\n",
    "        # Apply Accelerator backward which handles DeepSpeed, otherwise will call loss_grad.backward()\n",
    "        self.accelerator.backward(self.learn.loss_grad)\n",
    "        raise CancelBackwardException()\n",
    "\n",
    "    def before_train(self):    self.learn.dl = self._wrap_dl(self.learn.dl)\n",
    "    def before_validate(self): self.learn.dl = self._wrap_dl(self.learn.dl)\n",
    "    def after_fit(self): self.learn.model,self.learn.dls.loaders = self.learn.model.module,self.old_dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "@delegates(Accelerator, but=_hidden_params)\n",
    "def to_accelerate(self: Learner,\n",
    "        sync_bn=True, # Whether to replace all batch norm with `nn.SyncBatchNorm`\n",
    "        **kwargs\n",
    "    ):\n",
    "    \"Add `AcceleratedTrainer` to a learner, and configures an Accelerator\"\n",
    "    self.add_cb(AcceleratedTrainer(sync_bn, **kwargs))\n",
    "    if rank_distrib(): self.remove_cb(ProgressCallback)\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def detach_accelerate(self: Learner):\n",
    "    \"Remove `DistributedTrainer` from a learner\"\n",
    "    if num_distrib() <=1: return self\n",
    "    self.remove_cb(AcceleratedTrainer)\n",
    "    if rank_distrib() and not hasattr(self, 'progress'): self.add_cb(ProgressCallback())\n",
    "    return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `accelerate` context manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "@contextmanager\n",
    "@delegates(Accelerator, but=_hidden_params)\n",
    "def accelerate_ctx(self: Learner,\n",
    "        sync_bn=True, # Whether to replace all batch norm with `nn.SyncBatchNorm`\n",
    "        in_notebook=False, # Whether we are launching from a notebook or not\n",
    "        **kwargs\n",
    "   ):\n",
    "    \"A context manager to adapt a learner to train in distributed data parallel mode.\"\n",
    "    # Adapt self to DistributedDataParallel, yield, and cleanup afterwards.\n",
    "    cleanup_dpg = False\n",
    "    try:\n",
    "        if in_notebook:\n",
    "            cuda_id = rank_distrib()\n",
    "            if not torch.distributed.is_initialized():\n",
    "                setup_distrib(cuda_id)\n",
    "                cleanup_dpg = torch.distributed.is_initialized()\n",
    "            if not rank_distrib(): print(\"Training Learner...\")\n",
    "        if num_distrib(): self.to_accelerate(sync_bn, **kwargs)\n",
    "        yield self\n",
    "    finally:\n",
    "        self.detach_accelerate()\n",
    "        if cleanup_dpg: teardown_distrib()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`accelerate_ctx` prepares a learner to train in distributed data parallel mode with Accelerate. \n",
    "\n",
    "Typical usage:\n",
    "\n",
    "```\n",
    "with learn.accelerate_ctx(**kwargs): learn.fit(.....)\n",
    "```\n",
    "\n",
    "It attaches a `AcceleratedTrainer` callback and `DistributedDL` dataloader to  the learner, then executes `learn.fit(.....)`.  Upon exiting the context, it removes the `AcceleratedTrainer` and `DistributedDL`, and destroys any locally created distributed process group.  The process is still attached to the GPU though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Launcher\n",
    "\n",
    "Accelerate provides a [notebook_launcher](https://huggingface.co/docs/accelerate/launcher) functionality to let you keep using your Jupyter Notebook as you would, but train in a distributed setup!\n",
    "\n",
    "To utilize this functionality, migrate your training into a function, and pass this to `notebook_launcher`, such as:\n",
    "\n",
    "```python\n",
    "---\n",
    "from fastai.vision.all import *\n",
    "from fastai.accelerate import *\n",
    "\n",
    "set_seed(99, True)\n",
    "path = untar_data(URLs.PETS)/'images'\n",
    "dls = ImageDataLoaders.from_name_func(\n",
    "    path, get_image_files(path), valid_pct=0.2,\n",
    "    label_func=lambda x: x[0].isupper(), item_tfms=Resize(224))\n",
    "    \n",
    "learn = vision_learner(dls, resnet34, metrics=error_rate).to_fp16()\n",
    "\n",
    "def train():\n",
    "    with learn.accelerate_ctx(in_notebook=True):\n",
    "        learn.fine_tune(1)\n",
    "---\n",
    "from accelerate import notebook_launcher\n",
    "notebook_launcher(train, num_processes=2)\n",
    "---\n",
    "```\n",
    "\n",
    "> Note: You must specify the number of GPUs to use with `num_processes`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_torch_core.ipynb.\n",
      "Converted 01_layers.ipynb.\n",
      "Converted 01a_losses.ipynb.\n",
      "Converted 02_data.load.ipynb.\n",
      "Converted 03_data.core.ipynb.\n",
      "Converted 04_data.external.ipynb.\n",
      "Converted 05_data.transforms.ipynb.\n",
      "Converted 06_data.block.ipynb.\n",
      "Converted 07_vision.core.ipynb.\n",
      "Converted 08_vision.data.ipynb.\n",
      "Converted 09_vision.augment.ipynb.\n",
      "Converted 09b_vision.utils.ipynb.\n",
      "Converted 09c_vision.widgets.ipynb.\n",
      "Converted 10_tutorial.pets.ipynb.\n",
      "Converted 10b_tutorial.albumentations.ipynb.\n",
      "Converted 11_vision.models.xresnet.ipynb.\n",
      "Converted 12_optimizer.ipynb.\n",
      "Converted 13_callback.core.ipynb.\n",
      "Converted 13a_learner.ipynb.\n",
      "Converted 13b_metrics.ipynb.\n",
      "Converted 14_callback.schedule.ipynb.\n",
      "Converted 14a_callback.data.ipynb.\n",
      "Converted 15_callback.hook.ipynb.\n",
      "Converted 15a_vision.models.unet.ipynb.\n",
      "Converted 16_callback.progress.ipynb.\n",
      "Converted 17_callback.tracker.ipynb.\n",
      "Converted 18_callback.fp16.ipynb.\n",
      "Converted 18a_callback.training.ipynb.\n",
      "Converted 18b_callback.preds.ipynb.\n",
      "Converted 19_callback.mixup.ipynb.\n",
      "Converted 20_interpret.ipynb.\n",
      "Converted 20a_distributed.ipynb.\n",
      "Converted 20b_accelerate.ipynb.\n",
      "Converted 21_vision.learner.ipynb.\n",
      "Converted 22_tutorial.imagenette.ipynb.\n",
      "Converted 23_tutorial.vision.ipynb.\n",
      "Converted 24_tutorial.image_sequence.ipynb.\n",
      "Converted 24_tutorial.siamese.ipynb.\n",
      "Converted 24_vision.gan.ipynb.\n",
      "Converted 30_text.core.ipynb.\n",
      "Converted 31_text.data.ipynb.\n",
      "Converted 32_text.models.awdlstm.ipynb.\n",
      "Converted 33_text.models.core.ipynb.\n",
      "Converted 34_callback.rnn.ipynb.\n",
      "Converted 35_tutorial.wikitext.ipynb.\n",
      "Converted 37_text.learner.ipynb.\n",
      "Converted 38_tutorial.text.ipynb.\n",
      "Converted 39_tutorial.transformers.ipynb.\n",
      "Converted 40_tabular.core.ipynb.\n",
      "Converted 41_tabular.data.ipynb.\n",
      "Converted 42_tabular.model.ipynb.\n",
      "Converted 43_tabular.learner.ipynb.\n",
      "Converted 44_tutorial.tabular.ipynb.\n",
      "Converted 45_collab.ipynb.\n",
      "Converted 46_tutorial.collab.ipynb.\n",
      "Converted 50_tutorial.datablock.ipynb.\n",
      "Converted 60_medical.imaging.ipynb.\n",
      "Converted 61_tutorial.medical_imaging.ipynb.\n",
      "Converted 65_medical.text.ipynb.\n",
      "Converted 70_callback.wandb.ipynb.\n",
      "Converted 71_callback.tensorboard.ipynb.\n",
      "Converted 72_callback.neptune.ipynb.\n",
      "Converted 73_callback.captum.ipynb.\n",
      "Converted 74_huggingface.ipynb.\n",
      "Converted 97_test_utils.ipynb.\n",
      "Converted 99_pytorch_doc.ipynb.\n",
      "Converted dev-setup.ipynb.\n",
      "Converted app_examples.ipynb.\n",
      "Converted camvid.ipynb.\n",
      "Converted migrating_catalyst.ipynb.\n",
      "Converted migrating_ignite.ipynb.\n",
      "Converted migrating_lightning.ipynb.\n",
      "Converted migrating_pytorch.ipynb.\n",
      "Converted migrating_pytorch_verbose.ipynb.\n",
      "Converted ulmfit.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted quick_start.ipynb.\n",
      "Converted tutorial.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
